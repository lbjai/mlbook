---
interact_link: content/C:\Users\lbj\Desktop\book\content\04/04-5.ipynb
kernel_name: python3
has_widgets: false
title: '04-5 特征与多项式回归'
prev_page:
  url: /04/04-4
  title: '04-4 梯度下降 - 学习率'
next_page:
  url: /04/04-6
  title: '04-6 正规方程'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

### 特征与多项式回归

+  多项式回归


在房价预测问题中， 假设我们的特征数据为$x_1=frontage（临街宽度）$，$x_2=depth（纵向深度）$。

![](https://i.loli.net/2018/11/30/5c01013730fe3.png)
 
线性回归建模为：$$h_ \theta(x) =  \theta_0 +  \theta_1 \times frontage +  \theta_2 \times depth$$

但是我们可以自己创建一个特征 $x = Area(面积) = frontage \times depth$    
再进行建模：$$h_ \theta(x) =  \theta_0 +  \theta_1 \times Area $$  效果会好很多。 


线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型： 
$$h_ \theta(x) =  \theta_0 +  \theta_1 x_1 +  \theta_2 x^2_2$$
或者三次方模型：
$$h_ \theta(x) =  \theta_0 +  \theta_1 x_1 +  \theta_2 x^2_2 + \theta_3 x^3_3$$
 


![](https://i.loli.net/2018/11/30/5c01033105cf6.png) 


通常我们需要先观察数据然后再决定准备尝试怎样的模型。 另外，我们可以令： 
 $$x_2 = (size)^2$$
 $$x_3 = (size)^3$$
从而将模型转化为线性回归模型。 

根据函数图形特性，我们还可以使用： 
$$h_ \theta(x) =  \theta_0 +  \theta_1(size) +  \theta_2(size)^2$$
或者： 
$$h_ \theta(x) =  \theta_0 +  \theta_1(size) +  \theta_2\sqrt{(size)}$$ 

**注：如果我们采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要。因为幂运算很容易拉大特征之间尺度的差距** 

**牛刀小试**

Todo:  观察二次方模型和三次方模型拟合曲线的差异,思考,n 次方模型的 n 越大越好吗?


答：不是的, 合理的选择 n 非常重要。

