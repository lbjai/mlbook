---
interact_link: content/C:\Users\lbj\Desktop\book\content\08/08-6.ipynb
kernel_name: python3
has_widgets: false
title: '08-6 随机初始化'
prev_page:
  url: /08/08-5
  title: '08-5 梯度校验'
next_page:
  url: /08/08-7
  title: '08-7 把前面的内容放在一起'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

### 随机初始化

任何优化算法都需要一些初始的参数。到目前为止我们都是初始所有参数为 0，这样的
初始方法对于逻辑回归来说是可行的，但是对于神经网络来说是不可行的。

如果我们令所有的初始参数都为 0，这将意味着我们第二层的所有激活单元都会有相同的值。同理，如果我们初始所有的参数都为一个非 0 的数，结果也是一样的。 

我们通常初始参数为正负 ε 之间的随机值，假设我们要随机初始一个尺寸为 10×11 的参数矩阵，代码如下： 
Theta1 = rand(10, 11) * (2*eps) – eps 

![](https://i.loli.net/2018/12/02/5c03d6fa86f55.png)


**牛刀小试**

**通过numpy实现随机初始化**

<div markdown="1" class="cell code_cell">
<div class="input_area" markdown="1">
```python
import numpy as np
a= np.random.rand(10,11) # 机初始一个尺寸为 10×11 的参数矩阵
print(a)

```
</div>

<div class="output_wrapper" markdown="1">
<div class="output_subarea" markdown="1">
{:.output_stream}
```
[[0.89012924 0.08140487 0.95453883 0.10000767 0.99754677 0.63964653
  0.11652367 0.32366237 0.06493215 0.29949962 0.23932125]
 [0.34599237 0.28393063 0.50223968 0.8203895  0.70872595 0.2265806
  0.4533645  0.97246446 0.8904674  0.82028052 0.82447659]
 [0.72672059 0.11029451 0.17859903 0.90301048 0.71830531 0.95255698
  0.43121794 0.9719399  0.57803923 0.42545519 0.52678866]
 [0.97252596 0.73107581 0.6182679  0.61268221 0.56593853 0.21033142
  0.40632278 0.30804307 0.84622809 0.13058157 0.25621354]
 [0.86555812 0.36736487 0.92972801 0.14521097 0.89582942 0.18434383
  0.6729972  0.79367812 0.9795744  0.0741685  0.81361421]
 [0.60743163 0.99058131 0.09496072 0.6065123  0.1258677  0.36574205
  0.2549608  0.07228038 0.54149799 0.08674347 0.08558238]
 [0.08808488 0.36059832 0.00851983 0.48893007 0.60359639 0.74890883
  0.22425914 0.45415193 0.95099883 0.10464225 0.50671484]
 [0.23908324 0.87941705 0.6147011  0.57182956 0.58180014 0.25448078
  0.74614772 0.6257922  0.80234479 0.56125048 0.70141577]
 [0.03802879 0.04623665 0.6573583  0.49151533 0.86659065 0.18159533
  0.7612263  0.79319728 0.60322461 0.41638314 0.50906066]
 [0.67511789 0.51440033 0.76044891 0.62701232 0.87420669 0.1688621
  0.84625497 0.86893233 0.31110609 0.73861569 0.37070833]]
```
</div>
</div>
</div>
