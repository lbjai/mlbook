---
interact_link: content/C:\Users\lbj\Desktop\book\content\09/09-2.ipynb
kernel_name: python3
has_widgets: false
title: '09-2 假设检验'
prev_page:
  url: /09/09-1
  title: '09-1 决定下一步做什么'
next_page:
  url: /09/09-3
  title: '09-3 模型选择与训练集、验证集、测试集切分'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

### 假设检验

+ 如何评估假设函数
+ 训练集与测试集
+ 测试机误差计算

**评估假设函数**

 假设函数误差很小时,可能已经过拟合了。
 
那么，你该如何判断一个假设函数是过拟合的呢？对于这个简单的例子，我们可以对假设函数 h(x) 进行画图，然后观察图形趋势，但对于特征变量不止一个的这种一般情况，还有像有很多特征变量的问题，想要通过画出假设函数来进行观察，会变得很难甚至是不可能实现的。

因此，我们需要另一种方法来评估我们的假设函数过拟合检验。 

**训练集与测试集**

为了检验算法是否过拟合，我们将数据分成训练集和测试集，通常用70%的数据作为训练集，用剩下30%的数据作为测试集。

很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行“洗牌”，然后再分成训练集和测试集。 

![](https://i.loli.net/2018/12/01/5c0265f436958.png)

**测试集误差计算**

在通过训练集让我们的模型学习得出其参数后，对测试集运用该模型，我们有两种方式计算误差： 
1. 对于线性回归模型，我们利用测试数据集计算代价函数J ；



 $$J_{test}(\theta)=\frac{1}{2m_{test}}\sum^{m_{test}}_{i=1}({h_\theta(x^{(i)}_{test})-y^{(i)}_{test}})^2$$

2. 对于逻辑回归模型，我们可以利用测试数据集来计算代价函数： 
 


 
 $$J_{test}(\theta)=-\frac{1}{m_{test}}\sum^{m_{test}}_{i=1}y^{(i)}_{test}\log{h_\theta(x^{(i)}_{test})}+(1-y^{(i)}_{test}）\log{h_\theta(x^{(i)}_{test})}$$
 
也可以计算误分类的比率，对于每一个测试集实例，计算： 
 
![](https://i.loli.net/2018/12/01/5c0266a346bc2.png)
 
然后对计算结果求平均。 
 
 

$$J_{test}(\theta)=-\frac{1}{m_{test}}\sum^{m_{test}}_{i=1}y^{(i)}_{test}\log{h_\theta(x^{(i)}_{test})}+(1-y^{(i)}_{test}）\log{h_\theta(x^{(i)}_{test})}$$
